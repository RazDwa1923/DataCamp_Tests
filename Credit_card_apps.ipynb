{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the dataset\n",
    "cc_apps = pd.read_csv(\"Datasets/Credit_card_approvals/cc_approvals.data\", header=None)\n",
    "cc_apps.head()"
   ],
   "id": "9783f6730675f693"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# drop features 11 and 13 from the dataset\n",
    "cc_apps = cc_apps.drop([11, 13], axis=1)\n",
    "\n"
   ],
   "id": "d9836370df4e2a96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# splitting the data into train and test sets (test set is 33% of the data, random_state is 42)\n",
    "cc_apps_train, cc_apps_test = train_test_split(cc_apps, test_size=0.33, random_state=42)\n",
    "\n",
    "# replace '?' with NaN\n",
    "cc_apps_train_nans_replaced = cc_apps_train.replace('?', np.nan)\n",
    "cc_apps_test_nans_replaced = cc_apps_test.replace('?', np.nan)\n",
    "\n",
    "# create a table of missing values by column\n",
    "cc_apps_train_nans_replaced.isnull().sum()\n",
    "\n",
    "# convert datatype 1 to float in the train and test sets\n",
    "cc_apps_train_nans_replaced[1] = cc_apps_train_nans_replaced[1].astype(float)\n",
    "cc_apps_test_nans_replaced[1] = cc_apps_test_nans_replaced[1].astype(float)\n",
    "\n",
    "\n",
    "# get the data types of the columns\n",
    "cc_apps_train_nans_replaced.dtypes\n"
   ],
   "id": "a4b459dc9d8c4a74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Impute the missing values with mean imputation for columns 2, 7, 10, 14 for the train set\n",
    "# List of columns you want to impute\n",
    "columns_to_impute = [1, 2, 7, 10, 14]\n",
    "\n",
    "# Create a new DataFrame for the imputed data\n",
    "cc_apps_train_imputed = cc_apps_train_nans_replaced.copy()\n",
    "\n",
    "# Loop over the columns and impute them\n",
    "for column in columns_to_impute:\n",
    "    mean_value = cc_apps_train_imputed[column].mean()\n",
    "    cc_apps_train_imputed[column] = cc_apps_train_imputed[column].fillna(mean_value)\n",
    "\n",
    "# imputing the missing values with mean imputation for columns 2, 7, 10, 14 for the test set\n",
    "cc_apps_test_imputed = cc_apps_test_nans_replaced.copy()\n",
    "\n",
    "# Loop over the columns and impute them\n",
    "for column in columns_to_impute:\n",
    "    mean_value = cc_apps_test_imputed[column].mean()\n",
    "    cc_apps_test_imputed[column] = cc_apps_test_imputed[column].fillna(mean_value)\n"
   ],
   "id": "f0be5e8c79420b56"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# iterate through cc_apps_train_imputed columns with a for loop, checking for object data type and return the columns with object data type\n",
    "for column in cc_apps_train_imputed.columns:\n",
    "    if cc_apps_train_imputed[column].dtypes == 'object':\n",
    "        print(column)"
   ],
   "id": "77c008dfc886b2a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# impute the missing values for cc_apps_train_imputed and cc_apps_test_imputed using fillna method and the most frequent value using value_counts method\n",
    "for column in cc_apps_train_imputed.columns:\n",
    "    if cc_apps_train_imputed[column].dtypes == 'object':\n",
    "        cc_apps_train_imputed[column] = cc_apps_train_imputed[column].fillna(cc_apps_train_imputed[column].value_counts().index[0])\n",
    "        cc_apps_test_imputed[column] = cc_apps_test_imputed[column].fillna(cc_apps_test_imputed[column].value_counts().index[0])\n",
    "        "
   ],
   "id": "34307c309f57389c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert the categorical features in the train and test sets independently\n",
    "cc_apps_train_cat_encoding = pd.get_dummies(cc_apps_train_imputed)\n",
    "cc_apps_test_cat_encoding = pd.get_dummies(cc_apps_test_imputed)\n",
    "\n",
    "# Reindex the columns of the test set aligning with the train set\n",
    "cc_apps_test_cat_encoding = cc_apps_test_cat_encoding.reindex(\n",
    "    columns=cc_apps_train_cat_encoding.columns, fill_value=0\n",
    ")"
   ],
   "id": "d8e6acd22392d681"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# view the first five rows of the encoded train set\n",
    "cc_apps_train_cat_encoding.head()"
   ],
   "id": "f765ff85154642f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# create the X_train, X_test, y_train, y_test with the train and test sets (last column is target feature)\n",
    "X_train, y_train = (\n",
    "    cc_apps_train_cat_encoding.iloc[:, :-1].values,\n",
    "    cc_apps_train_cat_encoding.iloc[:, [-1]].values,\n",
    ")\n",
    "X_test, y_test = (\n",
    "    cc_apps_test_cat_encoding.iloc[:, :-1].values,\n",
    "    cc_apps_test_cat_encoding.iloc[:, [-1]].values,\n",
    ")\n"
   ],
   "id": "6801297e4d26c7e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# using minmax scaler to scale the train and test sets\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX_train = scaler.fit_transform(X_train)\n",
    "rescaledX_test = scaler.transform(X_test)\n",
    "\n",
    "# initiate the logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit the model to the train set\n",
    "logreg.fit(rescaledX_train, y_train)\n",
    "\n",
    "#use logreg to predict the test set\n",
    "y_pred = logreg.predict(rescaledX_test)\n",
    "\n",
    "#print the confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "id": "5b847c74aadfb6bc"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
